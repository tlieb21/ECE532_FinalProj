{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import statistics \n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n",
    "\n",
    "# Method for reading in the \"pickled\" object images\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "# Preprocessing- convert to greyscale\n",
    "def rgb2gray(im):\n",
    "    col_size = len(im[:,0])\n",
    "    im_out = np.empty([col_size,1024])\n",
    "    \n",
    "    for i in range(0,col_size):\n",
    "        for j in range(0,1024):\n",
    "            r = im[i,j] \n",
    "            g = im[i,j+1024]\n",
    "            b = im[i,j+2048]\n",
    "            im_out[i,j] = (0.2989 * r + 0.5870 * g + 0.1140 * b)\n",
    "    \n",
    "    return im_out\n",
    "\n",
    "# Each data_batch is a dictionary with the following items\n",
    "# b'batch_label --> specifies which batch it is\n",
    "# b'labels --> array of 10,000 labels 0-9 correspoding to the correct classification\n",
    "# b'data --> 10,000 x 3072 array of uint8 pixels, each rows is a 32x32 image with the first 1024 entries being the red,\n",
    "#            the second 1024 entries being the green, and the last 1024 entries being the blue\n",
    "\n",
    "db1_labels = data_batch_1[b'labels']\n",
    "db1_data = data_batch_1[b'data']\n",
    "db2_labels = data_batch_2[b'labels']\n",
    "db2_data = data_batch_2[b'data']\n",
    "db3_labels = data_batch_3[b'labels']\n",
    "db3_data = data_batch_3[b'data']\n",
    "db4_labels = data_batch_4[b'labels']\n",
    "db4_data = data_batch_4[b'data']\n",
    "db5_labels = data_batch_5[b'labels']\n",
    "db5_data = data_batch_5[b'data']\n",
    "db6_labels = test_batch[b'labels']\n",
    "db6_data = test_batch[b'data']\n",
    "tb_labels = test_batch[b'labels']\n",
    "tb_data = test_batch[b'data']\n",
    "\n",
    "\n",
    "db1_data = rgb2gray(db1_data)\n",
    "db2_data = rgb2gray(db2_data)\n",
    "db3_data = rgb2gray(db3_data)\n",
    "db4_data = rgb2gray(db4_data)\n",
    "db5_data = rgb2gray(db5_data)\n",
    "db6_data = rgb2gray(db6_data)\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbors(A, d, T, y, k):\n",
    "    train_size = len(A[:,0])\n",
    "    test_size = len(T[:,0])\n",
    "\n",
    "    distances = []\n",
    "    test_errors = np.zeros(test_size)\n",
    "    labels = np.zeros(test_size)\n",
    "    error_count = 0\n",
    "    \n",
    "    for i in range(0, test_size):\n",
    "        for j in range(0, train_size):\n",
    "            distances.append((np.linalg.norm(A[j,:]-T[i,:]),j))\n",
    "\n",
    "#     distances = np.sqrt((T**2).sum(axis=1)[:, np.newaxis] + (A**2).sum(axis=1) - 2 * T.dot(A.T))\n",
    "    # distances = np.sqrt((T**2).sum(axis=1)[:, np.newaxis] + (self.A**2).sum(axis=1) - 2 * T.dot(self.A.T))\n",
    "\n",
    "        sort_distances = sorted(distances)\n",
    "\n",
    "        k_nearest = sort_distances[:k]\n",
    "\n",
    "        k_labels = []\n",
    "        for dist, idx in k_nearest:\n",
    "            k_labels.append(d[idx])\n",
    "\n",
    "        labels[i] = statistics.mode(k_labels)\n",
    "\n",
    "        if labels[i] != y[i]:\n",
    "            error_count += 1\n",
    "        \n",
    "    # Calculate the errors and return them\n",
    "    error_rate = error_count / len(y)\n",
    "    squared_error = np.linalg.norm(labels - y)**2\n",
    "\n",
    "    return ([error_rate, squared_error])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n",
    "\n",
    "A = db2_data\n",
    "d = db2_labels\n",
    "T = db1_data[0:5000,:]\n",
    "y = db1_labels[0:5000]\n",
    "k = 1\n",
    "\n",
    "print(\"KNN Iteration 1\")\n",
    "[error_rate1, squared_error1] = k_nearest_neighbors(A, d, T, y, k)\n",
    "\n",
    "print(\"Error Rate: \" + str(round(error_rate1*100,3)) + \", Sqaured Error: \" + str(round(squared_error1,3)))\n",
    "print()\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKLearn KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n",
    "\n",
    "A = np.vstack((db2_data, db3_data, db4_data, db5_data, db6_data)) #Training matrix\n",
    "d = np.column_stack((np.array(db2_labels), np.array(db3_labels), np.array(db4_labels), np.array(db5_labels), np.array(db6_labels))).reshape(50000,1) #Known classifiers\n",
    "T = db1_data\n",
    "y = db1_labels\n",
    "\n",
    "train_size = len(A[:,0])\n",
    "test_size = len(T[:,0])\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3,algorithm='ball_tree',p=2)\n",
    "# knn = KNeighborsClassifier(n_neighbors=3,algorithm='kd_tree',p=2)\n",
    "knn.fit(A, d)\n",
    "\n",
    "error_count = 0\n",
    "labels = np.zeros(test_size)\n",
    "\n",
    "for i in range(0,test_size):\n",
    "    test = T[i,:].reshape((1,-1))\n",
    "    y_hat = knn.predict(test)\n",
    "    labels[i] = y_hat\n",
    "#     y_hat = knn.predict(T[i,:])\n",
    "    \n",
    "    if y_hat != y[i]:\n",
    "        error_count += 1\n",
    "    \n",
    "    \n",
    "error_rate = error_count / test_size\n",
    "squared_error = np.linalg.norm(labels - y)**2\n",
    "\n",
    "for i in range(0,20):\n",
    "    print(labels[i])\n",
    "\n",
    "\n",
    "print(\"Error Rate: \" + str(round(error_rate*100,3)) + \", Sqaured Error: \" + str(round(squared_error,3)))\n",
    "print()\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n",
    "print()\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
